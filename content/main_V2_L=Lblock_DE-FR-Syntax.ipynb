{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d4091c-4999-42db-998b-f648ddbb6145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting full-text Commentaire clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 48227/48227 [00:00<00:00, 117880.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 347 unique Commentaire full-text candidates (≥7 occurrences)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fuzzy clustering Commentaire (full text): 100%|█████████████████████████████████████| 347/347 [00:01<00:00, 181.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'commentaire_clusters_summary_fulltext.csv' with 204 rows.\n",
      "\n",
      "Correlating Type de constatation Texte to Commentaire clusters (vectorized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorized correlation:  25%|█████████████▉                                           | 50/204 [06:54<13:28,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 50: saved 1586 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorized correlation:  49%|███████████████████████████▍                            | 100/204 [13:41<09:28,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 100: saved 2772 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorized correlation:  74%|█████████████████████████████████████████▏              | 150/204 [21:57<09:35, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 150: saved 3856 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorized correlation:  98%|██████████████████████████████████████████████████████▉ | 200/204 [31:07<01:11, 17.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 200: saved 4764 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorized correlation: 100%|████████████████████████████████████████████████████████| 204/204 [33:55<00:00,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'commentaire_type_correlations_fulltext.csv' with 4823 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from rapidfuzz import fuzz, process\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "csv_file = \"20250903_Extrait_Constatations_F2.csv\"\n",
    "comment_col = \"Commentaire\"\n",
    "type_col = \"Type de constatation Texte\"\n",
    "\n",
    "comment_min_occurrences = 7\n",
    "threshold_similarity = 90\n",
    "max_typo_chars = 4\n",
    "fuzzy_match_threshold = 85\n",
    "checkpoint_every = 50\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def normalize_text(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = s.replace(\"\\xa0\", \" \").strip()\n",
    "    return s\n",
    "\n",
    "def clean_text_block(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = normalize_text(text).lower()\n",
    "    text = re.sub(r\"[^a-zà-öø-ÿœæçß0-9\\s-]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    words = [w for w in text.split() if len(w) > 1]\n",
    "    return \" \".join(words)\n",
    "\n",
    "def join_variations_with_counts(variants, counter, delim=\" | \"):\n",
    "    return delim.join([f\"{v} ({counter.get(v,0)})\" for v in variants])\n",
    "\n",
    "# ---------- LOAD CSV ----------\n",
    "df = pd.read_csv(csv_file, delimiter=\";\", dtype=str)\n",
    "df.columns = [normalize_text(c) for c in df.columns]\n",
    "\n",
    "if comment_col not in df.columns or type_col not in df.columns:\n",
    "    raise KeyError(f\"Expected columns '{comment_col}' and '{type_col}' not found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "df[comment_col] = df[comment_col].astype(str)\n",
    "df[type_col] = df[type_col].astype(str)\n",
    "\n",
    "# ---------- EXTRACT COMMENTAIRE CLUSTERS ----------\n",
    "print(\"\\nExtracting full-text Commentaire clusters...\")\n",
    "cleaned_comments = [clean_text_block(t) for t in tqdm(df[comment_col])]\n",
    "cluster_counter = Counter(cleaned_comments)\n",
    "total_cluster_instances = sum(cluster_counter.values())\n",
    "candidates = {k: v for k, v in cluster_counter.items() if v >= comment_min_occurrences}\n",
    "print(f\"Found {len(candidates)} unique Commentaire full-text candidates (≥{comment_min_occurrences} occurrences)\")\n",
    "\n",
    "# ---------- FUZZY CLUSTERING ----------\n",
    "cluster_groups = {}\n",
    "for cluster in tqdm(candidates.keys(), desc=\"Fuzzy clustering Commentaire (full text)\"):\n",
    "    found = False\n",
    "    for rep in list(cluster_groups.keys()):\n",
    "        sim = fuzz.ratio(cluster, rep)\n",
    "        edit_d = Levenshtein.distance(cluster, rep)\n",
    "        if sim >= threshold_similarity or edit_d <= max_typo_chars:\n",
    "            cluster_groups[rep].append(cluster)\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        cluster_groups[cluster] = [cluster]\n",
    "\n",
    "# ---------- AGGREGATE COMMENTAIRE CLUSTERS ----------\n",
    "comment_summary_rows = []\n",
    "for rep, variants in cluster_groups.items():\n",
    "    cnt = sum(cluster_counter.get(v, 0) for v in variants)\n",
    "    per_mille = round(cnt / total_cluster_instances * 1000, 2) if total_cluster_instances > 0 else 0\n",
    "    variations_text = join_variations_with_counts(variants, cluster_counter)\n",
    "    comment_summary_rows.append({\n",
    "        \"Cluster_Representative\": rep,\n",
    "        \"Count\": cnt,\n",
    "        \"Variations\": variations_text,\n",
    "        \"PerMille\": per_mille,\n",
    "    })\n",
    "\n",
    "comment_summary_df = pd.DataFrame(comment_summary_rows).sort_values(by=\"Count\", ascending=False)\n",
    "comment_summary_df.to_csv(\"commentaire_clusters_summary_fulltext.csv\", sep=\";\", index=False)\n",
    "print(\"Saved 'commentaire_clusters_summary_fulltext.csv' with\", len(comment_summary_df), \"rows.\")\n",
    "\n",
    "# ---------- CORRELATE COMMENTAIRES ↔ TYPE ----------\n",
    "print(\"\\nCorrelating Type de constatation Texte to Commentaire clusters (vectorized)...\")\n",
    "comment_texts = [c.lower() for c in cleaned_comments]\n",
    "type_values = df[type_col].tolist()\n",
    "corr_rows = []\n",
    "\n",
    "for i, (rep, variants) in enumerate(tqdm(cluster_groups.items(), desc=\"Vectorized correlation\")):\n",
    "    matches = process.cdist([rep], comment_texts, scorer=fuzz.partial_ratio)\n",
    "    matched_indices = [j for j, score in enumerate(matches[0]) if score >= fuzzy_match_threshold]\n",
    "    if not matched_indices:\n",
    "        continue\n",
    "    matched_types = [type_values[j] for j in matched_indices]\n",
    "    type_counts = Counter(matched_types)\n",
    "    total_type_count = sum(type_counts.values())\n",
    "    for t_val, t_cnt in type_counts.items():\n",
    "        t_per_mille = round(t_cnt / total_type_count * 1000, 2)\n",
    "        corr_rows.append({\n",
    "            \"Commentaire_Cluster\": rep,\n",
    "            \"Commentaire_Variations\": join_variations_with_counts(variants, cluster_counter),\n",
    "            \"Commentaire_Count\": sum(cluster_counter.get(v, 0) for v in variants),\n",
    "            \"Type_Value\": t_val,\n",
    "            \"Type_Count\": t_cnt,\n",
    "            \"Type_PerMille\": t_per_mille,\n",
    "        })\n",
    "\n",
    "    if (i + 1) % checkpoint_every == 0:\n",
    "        partial_df = pd.DataFrame(corr_rows)\n",
    "        partial_df.to_csv(f\"partial_corr_checkpoint_{i+1}_fulltext.csv\", sep=\";\", index=False)\n",
    "        print(f\"Checkpoint {i+1}: saved {len(partial_df)} rows.\")\n",
    "\n",
    "corr_df = pd.DataFrame(corr_rows)\n",
    "corr_df.to_csv(\"commentaire_type_correlations_fulltext.csv\", sep=\";\", index=False)\n",
    "print(\"Saved 'commentaire_type_correlations_fulltext.csv' with\", len(corr_df), \"rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda8060-3dde-4d82-863b-43dd7794bfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
